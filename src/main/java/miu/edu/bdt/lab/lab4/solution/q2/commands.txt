[cloudera@quickstart ~]$  hadoop jar big-data-technology-1.0-SNAPSHOT-jar-with-dependencies.jar input output /home/cloudera/weather.avsc
Avro Station-Temp-Year is running!!!!!
SCHEMA: {"type":"record","name":"WeatherRecord","doc":"A weather reading.","fields":[{"name":"stationId","type":"string"},{"name":"temperature","type":"float","order":"descending"},{"name":"year","type":"string"}]}
23/04/09 22:32:57 INFO client.RMProxy: Connecting to ResourceManager at quickstart.cloudera/172.17.0.2:8032
23/04/09 22:32:58 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
23/04/09 22:32:59 INFO input.FileInputFormat: Total input paths to process : 1
23/04/09 22:32:59 INFO mapreduce.JobSubmitter: number of splits:1
23/04/09 22:32:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1680923415634_0041
23/04/09 22:33:00 INFO impl.YarnClientImpl: Submitted application application_1680923415634_0041
23/04/09 22:33:00 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1680923415634_0041/
23/04/09 22:33:00 INFO mapreduce.Job: Running job: job_1680923415634_0041
23/04/09 22:33:07 INFO mapreduce.Job: Job job_1680923415634_0041 running in uber mode : false
23/04/09 22:33:07 INFO mapreduce.Job:  map 0% reduce 0%
23/04/09 22:33:12 INFO mapreduce.Job:  map 100% reduce 0%
23/04/09 22:33:17 INFO mapreduce.Job:  map 100% reduce 100%
23/04/09 22:33:17 INFO mapreduce.Job: Job job_1680923415634_0041 completed successfully
23/04/09 22:33:17 INFO mapreduce.Job: Counters: 49
        File System Counters
                FILE: Number of bytes read=208
                FILE: Number of bytes written=238641
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=2635
                HDFS: Number of bytes written=651
                HDFS: Number of read operations=6
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Job Counters
                Launched map tasks=1
                Launched reduce tasks=1
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=337792
                Total time spent by all reduces in occupied slots (ms)=319488
                Total time spent by all map tasks (ms)=2639
                Total time spent by all reduce tasks (ms)=2496
                Total vcore-seconds taken by all map tasks=2639
                Total vcore-seconds taken by all reduce tasks=2496
                Total megabyte-seconds taken by all map tasks=337792
                Total megabyte-seconds taken by all reduce tasks=319488
        Map-Reduce Framework
                Map input records=20
                Map output records=20
                Map output bytes=440
                Map output materialized bytes=204
                Input split bytes=139
                Combine input records=0
                Combine output records=0
                Reduce input groups=17
                Reduce shuffle bytes=204
                Reduce input records=20
                Reduce output records=17
                Spilled Records=40
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=260
                CPU time spent (ms)=2380
                Physical memory (bytes) snapshot=285044736
                Virtual memory (bytes) snapshot=3923865600
                Total committed heap usage (bytes)=84934656
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=2496
        File Output Format Counters
                Bytes Written=651
Avro Station-Temp-Year is done!!!!!
[cloudera@quickstart ~]$ avro-tools tojson hdfs://localhost/user/cloudera/output/part-r-00000.avro
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
{"stationId":"011990-99999","temperature":30.0,"year":"2018"}
{"stationId":"011990-99999","temperature":2.2,"year":"1950"}
{"stationId":"011990-99999","temperature":2.2,"year":"2018"}
{"stationId":"011990-99999","temperature":0.0,"year":"1950"}
{"stationId":"011990-99999","temperature":-1.1,"year":"1950"}
{"stationId":"012650-99999","temperature":11.1,"year":"1949"}
{"stationId":"012650-99999","temperature":7.8,"year":"1949"}
{"stationId":"029070-99999","temperature":-5.6,"year":"1901"}
{"stationId":"029070-99999","temperature":-6.1,"year":"1901"}
{"stationId":"029070-99999","temperature":-7.2,"year":"1901"}
{"stationId":"029070-99999","temperature":-7.8,"year":"1901"}
{"stationId":"029070-99999","temperature":-9.4,"year":"1901"}
{"stationId":"029810-99999","temperature":2.2,"year":"1902"}
{"stationId":"029810-99999","temperature":1.7,"year":"1902"}
{"stationId":"029810-99999","temperature":1.1,"year":"1902"}
{"stationId":"029810-99999","temperature":0.6,"year":"1902"}
{"stationId":"029810-99999","temperature":-0.6,"year":"1902"}
[cloudera@quickstart ~]$
